{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting sentiment from product reviews\n",
    "\n",
    "\n",
    "The goal of this first notebook is to explore logistic regression and feature engineering with existing GraphLab functions.\n",
    "\n",
    "In this notebook you will use product review data from Amazon.com to predict whether the sentiments about a product (from its reviews) are positive or negative.\n",
    "\n",
    "* Use SFrames to do some feature engineering\n",
    "* Train a logistic regression model to predict the sentiment of product reviews.\n",
    "* Inspect the weights (coefficients) of a trained logistic regression model.\n",
    "* Make a prediction (both class and probability) of sentiment for a new product review.\n",
    "* Given the logistic regression weights, predictors and ground truth labels, write a function to compute the **accuracy** of the model.\n",
    "* Inspect the coefficients of the logistic regression model and interpret their meanings.\n",
    "* Compare multiple logistic regression models.\n",
    "\n",
    "Let's get started!\n",
    "    \n",
    "## Fire up GraphLab Create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have the latest version of GraphLab Create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import graphlab\n",
    "import math\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preperation\n",
    "\n",
    "We will use a dataset consisting of baby product reviews on Amazon.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"9392,\"RT @RunyonHailey: What are we gonna throw @ football games? No baby powder or corn starch. \"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"9392,\"RT @RunyonHailey: What are we gonna throw @ football games? No baby powder or corn starch. \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"19239,\"RT @Zedd: so now u know:\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"19239,\"RT @Zedd: so now u know:\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"- i'm in ibiza\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"- i'm in ibiza\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"FLOUR! \"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"FLOUR! \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"- I'm in my underwear\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"- I'm in my underwear\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"@RunyonAbby : we can't cuz of those glu…\",Fri Sep 09 15:33:18 +0000 2016,0.221402,1\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"@RunyonAbby : we can't cuz of those glu…\",Fri Sep 09 15:33:18 +0000 2016,0.221402,1\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"- i have a new song\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"- i have a new song\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"- ^ deadline is today\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"- ^ deadline is today\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"- @tnorris is a corn dog\",Fri Sep 09 21:59:20 +0000 2016,0.439239,1\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"- @tnorris is a corn dog\",Fri Sep 09 21:59:20 +0000 2016,0.439239,1\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"46,\"RT @OreFakorede: Shameless, 'lick your face in public' love.\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"46,\"RT @OreFakorede: Shameless, 'lick your face in public' love.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"19243,\"RT @dtboyg: CANDY CORN IS THE NASTIEST CANDY\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"19243,\"RT @dtboyg: CANDY CORN IS THE NASTIEST CANDY\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>8354 lines failed to parse correctly</pre>"
      ],
      "text/plain": [
       "8354 lines failed to parse correctly"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Anton\\output11_v22.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Anton\\output11_v22.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.128065 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.128065 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,long,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"9392,\"RT @RunyonHailey: What are we gonna throw @ football games? No baby powder or corn starch. \"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"9392,\"RT @RunyonHailey: What are we gonna throw @ football games? No baby powder or corn starch. \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"19239,\"RT @Zedd: so now u know:\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"19239,\"RT @Zedd: so now u know:\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"FLOUR! \"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"FLOUR! \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"- i'm in ibiza\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"- i'm in ibiza\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"- I'm in my underwear\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"- I'm in my underwear\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"46,\"RT @OreFakorede: Shameless, 'lick your face in public' love.\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"46,\"RT @OreFakorede: Shameless, 'lick your face in public' love.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"@RunyonAbby : we can't cuz of those glu…\",Fri Sep 09 15:33:18 +0000 2016,0.221402,1\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"@RunyonAbby : we can't cuz of those glu…\",Fri Sep 09 15:33:18 +0000 2016,0.221402,1\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"- i have a new song\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"- i have a new song\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"The 'eat corn and coconut together' or 'explore the Bahamas' kind of love.\",Fri Sep 09 06:10:14 +0000 2016,0,0\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"The 'eat corn and coconut together' or 'explore the Bahamas' kind of love.\",Fri Sep 09 06:10:14 +0000 2016,0,0\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"9407,\"Now on Refresh hits #Boostee-Pop Corn https://t.co/vydADLr5Lq\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"9407,\"Now on Refresh hits #Boostee-Pop Corn https://t.co/vydADLr5Lq\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"- ^ deadline is today\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"- ^ deadline is today\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"52,\"*blinks in shock before sagging a bit*\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"52,\"*blinks in shock before sagging a bit*\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>8355 lines failed to parse correctly</pre>"
      ],
      "text/plain": [
       "8355 lines failed to parse correctly"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Anton\\output11_v22.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Anton\\output11_v22.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 16735 lines in 0.102092 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 16735 lines in 0.102092 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "products = graphlab.SFrame('output11_v22.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us see a preview of what the dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">X1</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">text</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">prct_change</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">RT @melissasraja:<br>Valentines Day candy  ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Fri Sep 09 06:07:27 +0000<br>2016 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">#corn sex milton twins<br>porn ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Fri Sep 09 06:07:51 +0000<br>2016 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">The movies. The<br>temperature. The hay ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Fri Sep 09 06:07:56 +0000<br>2016 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">RT @ESPNNBA: Corn Mazes:<br>NBA Championship edit ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Fri Sep 09 06:07:58 +0000<br>2016 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">11</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Corn on the Cob - You<br>Suck at Cooking (episode ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Fri Sep 09 06:08:03 +0000<br>2016 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Macaroni soup with<br>potatoes, carrots and ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Fri Sep 09 06:08:28 +0000<br>2016 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">16</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Mainly because I REALLY<br>wanna give myself some ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Fri Sep 09 06:08:32 +0000<br>2016 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">17</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">The corn Spain<br>https://t.co/4gigizQOtZ ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Fri Sep 09 06:08:45 +0000<br>2016 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">19</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">RT @YukiJorouge: [asmr]<br>weeb sucks a corn dog ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Fri Sep 09 06:08:51 +0000<br>2016 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">20</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">@aatikah98 ya! Pop corn<br>hahaha ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Fri Sep 09 06:09:02 +0000<br>2016 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[16735 rows x 5 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tX1\tstr\n",
       "\ttext\tstr\n",
       "\ttime\tstr\n",
       "\tprct_change\tint\n",
       "\tsentiment\tint\n",
       "\n",
       "Rows: 16735\n",
       "\n",
       "Data:\n",
       "+----+--------------------------------+--------------------------------+-------------+\n",
       "| X1 |              text              |              time              | prct_change |\n",
       "+----+--------------------------------+--------------------------------+-------------+\n",
       "| 0  | RT @melissasraja: Valentin...  | Fri Sep 09 06:07:27 +0000 2016 |      0      |\n",
       "| 4  | #corn sex milton twins por...  | Fri Sep 09 06:07:51 +0000 2016 |      0      |\n",
       "| 8  | The movies. The temperatur...  | Fri Sep 09 06:07:56 +0000 2016 |      0      |\n",
       "| 9  | RT @ESPNNBA: Corn Mazes: N...  | Fri Sep 09 06:07:58 +0000 2016 |      0      |\n",
       "| 11 | Corn on the Cob - You Suck...  | Fri Sep 09 06:08:03 +0000 2016 |      0      |\n",
       "| 15 | Macaroni soup with potatoe...  | Fri Sep 09 06:08:28 +0000 2016 |      0      |\n",
       "| 16 | Mainly because I REALLY wa...  | Fri Sep 09 06:08:32 +0000 2016 |      0      |\n",
       "| 17 | The corn Spain https://t.c...  | Fri Sep 09 06:08:45 +0000 2016 |      0      |\n",
       "| 19 | RT @YukiJorouge: [asmr] we...  | Fri Sep 09 06:08:51 +0000 2016 |      0      |\n",
       "| 20 | @aatikah98 ya! Pop corn hahaha | Fri Sep 09 06:09:02 +0000 2016 |      0      |\n",
       "+----+--------------------------------+--------------------------------+-------------+\n",
       "+-----------+\n",
       "| sentiment |\n",
       "+-----------+\n",
       "|     0     |\n",
       "|     0     |\n",
       "|     0     |\n",
       "|     0     |\n",
       "|     0     |\n",
       "|     0     |\n",
       "|     0     |\n",
       "|     0     |\n",
       "|     0     |\n",
       "|     0     |\n",
       "+-----------+\n",
       "[16735 rows x 5 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the word count vector for each review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explore a specific example of a baby product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X1': '551',\n",
       " 'prct_change': 0L,\n",
       " 'sentiment': 0L,\n",
       " 'text': \"RT @sidkneecap: y do ppl keep telling me it looks like I've lost weight like bitch WHERE I look like a corn dog\",\n",
       " 'time': 'Fri Sep 09 06:46:41 +0000 2016'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[269]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will perform 2 simple data transformations:\n",
    "\n",
    "1. Remove punctuation using [Python's built-in](https://docs.python.org/2/library/string.html) string functionality.\n",
    "2. Transform the reviews into word-counts.\n",
    "\n",
    "**Aside**. In this notebook, we remove all punctuations for the sake of simplicity. A smarter approach to punctuations would preserve phrases such as \"I'd\", \"would've\", \"hadn't\" and so forth. See [this page](https://www.cis.upenn.edu/~treebank/tokenization.html) for an example of smart handling of punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return text.translate(None, string.punctuation) \n",
    "\n",
    "review_without_puctuation = products['text'].apply(remove_punctuation)\n",
    "products['word_count'] = graphlab.text_analytics.count_words(review_without_puctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us explore what the sample example above looks like after these 2 transformations. Here, each entry in the **word_count** column is a dictionary where the key is the word and the value is a count of the number of times the word occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1L,\n",
       " 'bitch': 1L,\n",
       " 'corn': 1L,\n",
       " 'do': 1L,\n",
       " 'dog': 1L,\n",
       " 'i': 1L,\n",
       " 'it': 1L,\n",
       " 'ive': 1L,\n",
       " 'keep': 1L,\n",
       " 'like': 3L,\n",
       " 'look': 1L,\n",
       " 'looks': 1L,\n",
       " 'lost': 1L,\n",
       " 'me': 1L,\n",
       " 'ppl': 1L,\n",
       " 'rt': 1L,\n",
       " 'sidkneecap': 1L,\n",
       " 'telling': 1L,\n",
       " 'weight': 1L,\n",
       " 'where': 1L,\n",
       " 'y': 1L}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[269]['word_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract sentiments\n",
    "\n",
    "We will **ignore** all reviews with *rating = 3*, since they tend to have a neutral sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15218"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = products[products['sentiment'] != 0]\n",
    "len(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will assign reviews with a rating of 4 or higher to be *positive* reviews, while the ones with rating of 2 or lower are *negative*. For the sentiment column, we use +1 for the positive class label and -1 for the negative class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
    "#products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see that the dataset contains an extra column called **sentiment** which is either positive (+1) or negative (-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform a train/test split with 80% of the data in the training set and 20% of the data in the test set. We use `seed=1` so that everyone gets the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12175\n",
      "3043\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = products.random_split(.8, seed=1)\n",
    "print len(train_data)\n",
    "print len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a sentiment classifier with logistic regression\n",
    "\n",
    "We will now use logistic regression to create a sentiment classifier on the training data. This model will use the column **word_count** as a feature and the column **sentiment** as the target. We will use `validation_set=None` to obtain same results as everyone else.\n",
    "\n",
    "**Note:** This line may take 1-2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 12175</pre>"
      ],
      "text/plain": [
       "Number of examples          : 12175"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 1</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 23209</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 23209"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 23210</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 23210"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.000082  | 1.127833     | 0.831294          |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.000082  | 1.127833     | 0.831294          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 1.192306     | 0.898891          |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 1.192306     | 0.898891          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 1.227338     | 0.929035          |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 1.227338     | 0.929035          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 1.263374     | 0.949076          |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 1.263374     | 0.949076          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 1.297403     | 0.949979          |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 1.297403     | 0.949979          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 1.331433     | 0.948501          |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 1.331433     | 0.948501          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>TERMINATED: Iteration limit reached.</pre>"
      ],
      "text/plain": [
       "TERMINATED: Iteration limit reached."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>This model may not be optimal. To improve it, consider increasing `max_iterations`.</pre>"
      ],
      "text/plain": [
       "This model may not be optimal. To improve it, consider increasing `max_iterations`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_model = graphlab.logistic_classifier.create(train_data,\n",
    "                                                      target = 'sentiment',\n",
    "                                                      features=['word_count'],\n",
    "                                                      validation_set=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class                          : LogisticClassifier\n",
       "\n",
       "Schema\n",
       "------\n",
       "Number of coefficients         : 23210\n",
       "Number of examples             : 12175\n",
       "Number of classes              : 2\n",
       "Number of feature columns      : 1\n",
       "Number of unpacked features    : 23209\n",
       "\n",
       "Hyperparameters\n",
       "---------------\n",
       "L1 penalty                     : 0.0\n",
       "L2 penalty                     : 0.01\n",
       "\n",
       "Training Summary\n",
       "----------------\n",
       "Solver                         : lbfgs\n",
       "Solver iterations              : 10\n",
       "Solver status                  : TERMINATED: Iteration limit reached.\n",
       "Training time (sec)            : 1.5036\n",
       "\n",
       "Settings\n",
       "--------\n",
       "Log-likelihood                 : 1154.8262\n",
       "\n",
       "Highest Positive Coefficients\n",
       "-----------------------------\n",
       "word_count[httpstconr3lvp32y7] : 9.4529\n",
       "word_count[mitchelbosko1]      : 7.9025\n",
       "word_count[httpstco4mzcwgrgqi] : 7.3323\n",
       "word_count[atidavefogel]       : 7.1902\n",
       "word_count[anarojas]           : 7.1864\n",
       "\n",
       "Lowest Negative Coefficients\n",
       "----------------------------\n",
       "word_count[httpstcogctblwskbc] : -21.5544\n",
       "word_count[httpstco2fwpnkmlv7] : -21.5544\n",
       "word_count[httpstcorwrfn7oucy] : -21.5544\n",
       "word_count[convince]           : -12.2665\n",
       "word_count[httpstcof9z3takxp3] : -10.6137"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aside**. You may get an warning to the effect of \"Terminated due to numerical difficulties --- this model may not be ideal\". It means that the quality metric (to be covered in Module 3) failed to improve in the last iteration of the run. The difficulty arises as the sentiment model puts too much weight on extremely rare words. A way to rectify this is to apply regularization, to be covered in Module 4. Regularization lessens the effect of extremely rare words. For the purpose of this assignment, however, please proceed with the model above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fitted the model, we can extract the weights (coefficients) as an SFrame as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'index', 'class', 'value', 'stderr']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = sentiment_model.coefficients\n",
    "weights.column_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of `121713` coefficients in the model. Recall from the lecture that positive weights $w_j$ correspond to weights that cause positive sentiment, while negative weights correspond to negative sentiment. \n",
    "\n",
    "Fill in the following block of code to calculate how many *weights* are positive ( >= 0). (**Hint**: The `'value'` column in SFrame *weights* must be positive ( >= 0))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive weights: 17525 \n",
      "Number of negative weights: 5685 \n"
     ]
    }
   ],
   "source": [
    "num_positive_weights = len(weights[weights['value'] >= 0])\n",
    "num_negative_weights = len(weights[weights['value'] < 0])\n",
    "\n",
    "print \"Number of positive weights: %s \" % num_positive_weights\n",
    "print \"Number of negative weights: %s \" % num_negative_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz question:** How many weights are >= 0?  68419 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with logistic regression\n",
    "\n",
    "Now that a model is trained, we can make predictions on the **test data**. In this section, we will explore this in the context of 3 examples in the test dataset.  We refer to this set of 3 examples as the **sample_test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1L, -1L, -1L]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">X1</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">text</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">prct_change</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sentiment</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">word_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">917</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">RT @busquetsmarcelo:<br>$CORN  #corn   trading ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Fri Sep 09 07:12:00 +0000<br>2016 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'alza': 1L, 'rt': 1L,<br>'ahi': 1L, 'para': 1L, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">941</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Corn dogs, look like the<br>dogs are wearing .. down ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Fri Sep 09 07:14:38 +0000<br>2016 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'wearing': 1L, 'look':<br>1L, 'corn': 1L, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">971</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">RT @AgsPlayers: Expected<br>Chinese corn crop dec ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Fri Sep 09 07:16:27 +0000<br>2016 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'rt': 1L, 'decline': 1L,<br>'usda': 1L, 'chinese': ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[3 rows x 6 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tX1\tstr\n",
       "\ttext\tstr\n",
       "\ttime\tstr\n",
       "\tprct_change\tint\n",
       "\tsentiment\tint\n",
       "\tword_count\tdict\n",
       "\n",
       "Rows: 3\n",
       "\n",
       "Data:\n",
       "+-----+-------------------------------+--------------------------------+-------------+\n",
       "|  X1 |              text             |              time              | prct_change |\n",
       "+-----+-------------------------------+--------------------------------+-------------+\n",
       "| 917 | RT @busquetsmarcelo: $CORN... | Fri Sep 09 07:12:00 +0000 2016 |      0      |\n",
       "| 941 | Corn dogs, look like the d... | Fri Sep 09 07:14:38 +0000 2016 |      0      |\n",
       "| 971 | RT @AgsPlayers: Expected C... | Fri Sep 09 07:16:27 +0000 2016 |      0      |\n",
       "+-----+-------------------------------+--------------------------------+-------------+\n",
       "+-----------+-------------------------------+\n",
       "| sentiment |           word_count          |\n",
       "+-----------+-------------------------------+\n",
       "|     -1    | {'alza': 1L, 'rt': 1L, 'ah... |\n",
       "|     -1    | {'wearing': 1L, 'look': 1L... |\n",
       "|     -1    | {'rt': 1L, 'decline': 1L, ... |\n",
       "+-----------+-------------------------------+\n",
       "[3 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data = test_data[10:13]\n",
    "print sample_test_data['sentiment']\n",
    "sample_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dig deeper into the first row of the **sample_test_data**. Here's the full review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"RT @busquetsmarcelo: $CORN  #corn   trading 30'   veremos si retrae a 324 para ahi si comenzar a perfilar alza consistente. https://t.co/fS\\x85\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data[0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That review seems pretty positive.\n",
    "\n",
    "Now, let's see what the next row of the **sample_test_data** looks like. As we could guess from the sentiment (-1), the review is quite negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @AgsPlayers: Expected Chinese corn crop decline less than USDA ideas - RJO'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data[2]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now make a **class** prediction for the **sample_test_data**. The `sentiment_model` should predict **+1** if the sentiment is positive and **-1** if the sentiment is negative. Recall from the lecture that the **score** (sometimes called **margin**) for the logistic regression model  is defined as:\n",
    "\n",
    "$$\n",
    "\\mbox{score}_i = \\mathbf{w}^T h(\\mathbf{x}_i)\n",
    "$$ \n",
    "\n",
    "where $h(\\mathbf{x}_i)$ represents the features for example $i$.  We will write some code to obtain the **scores** using GraphLab Create. For each row, the **score** (or margin) is a number in the range **[-inf, inf]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.3684470938060156, -2.7209859174219257, -2.9440030809974265]\n"
     ]
    }
   ],
   "source": [
    "scores = sentiment_model.predict(sample_test_data, output_type='margin')\n",
    "print scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting sentiment\n",
    "\n",
    "These scores can be used to make class predictions as follows:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & \\mathbf{w}^T h(\\mathbf{x}_i) > 0 \\\\\n",
    "      -1 & \\mathbf{w}^T h(\\mathbf{x}_i) \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Using scores, write code to calculate $\\hat{y}$, the class predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ytag = np.sign(scores)\n",
    "print ytag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to verify that the class predictions obtained by your calculations are the same as that obtained from GraphLab Create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class predictions according to GraphLab Create:\n",
      "[1L, -1L, -1L]\n"
     ]
    }
   ],
   "source": [
    "print \"Class predictions according to GraphLab Create:\" \n",
    "print sentiment_model.predict(sample_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**: Make sure your class predictions match with the one obtained from GraphLab Create.\n",
    "\n",
    "### Probability predictions\n",
    "\n",
    "Recall from the lectures that we can also calculate the probability predictions from the scores using:\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))}.\n",
    "$$\n",
    "\n",
    "Using the variable **scores** calculated previously, write code to calculate the probability that a sentiment is positive using the above formula. For each row, the probabilities should be a number in the range **[0, 1]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9667037430216904, 0.06174632371879778, 0.050020709224901226]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "probytag = math.e**(-scores)\n",
    "probytagscores = 1/(1+probytag)\n",
    "print probytagscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**: Make sure your probability predictions match the ones obtained from GraphLab Create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class predictions according to GraphLab Create:\n",
      "[0.9667037430216904, 0.06174632371879779, 0.0500207092249012]\n"
     ]
    }
   ],
   "source": [
    "print \"Class predictions according to GraphLab Create:\" \n",
    "print sentiment_model.predict(sample_test_data, output_type='probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quiz Question:** Of the three data points in **sample_test_data**, which one (first, second, or third) has the **lowest probability** of being classified as a positive review? Third"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most positive (and negative) review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now turn to examining the full test dataset, **test_data**, and use GraphLab Create to form predictions on all of the test data points for faster performance.\n",
    "\n",
    "Using the `sentiment_model`, find the 20 reviews in the entire **test_data** with the **highest probability** of being classified as a **positive review**. We refer to these as the \"most positive reviews.\"\n",
    "\n",
    "To calculate these top-20 reviews, use the following steps:\n",
    "1.  Make probability predictions on **test_data** using the `sentiment_model`. (**Hint:** When you call `.predict` to make predictions on the test data, use option `output_type='probability'` to output the probability rather than just the most likely class.)\n",
    "2.  Sort the data according to those predictions and pick the top 20. (**Hint:** You can use the `.topk` method on an SFrame to find the top k rows sorted according to the value of a specified column.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------------+--------------------------------+-------------+\n",
      "|   X1  |              text             |              time              | prct_change |\n",
      "+-------+-------------------------------+--------------------------------+-------------+\n",
      "| 26516 | RT @congress_nagpur: Ex Un... | Sat Sep 10 03:39:33 +0000 2016 |      0      |\n",
      "| 11779 | RT @congress_nagpur: Ex Un... | Fri Sep 09 17:00:18 +0000 2016 |      0      |\n",
      "|  9384 | #d?deblomster 3) s?t Allan... | Fri Sep 09 15:33:00 +0000 2016 |      0      |\n",
      "| 11924 | RT congress_nagpur: Ex Uni... | Fri Sep 09 17:05:31 +0000 2016 |      0      |\n",
      "| 26749 | @SampleAgri @DallasSansom ... | Sat Sep 10 03:51:56 +0000 2016 |      0      |\n",
      "| 13768 | Idgaf if I start an argume... | Fri Sep 09 18:23:27 +0000 2016 |      0      |\n",
      "| 12576 | RT @mdgblogger: Vegan Corn... | Fri Sep 09 17:30:01 +0000 2016 |      0      |\n",
      "| 27086 | @overtflow overtflow caugh... | Sat Sep 10 04:12:23 +0000 2016 |      0      |\n",
      "| 20283 | Dusk- the glow of Bindweed... | Fri Sep 09 22:48:36 +0000 2016 |      0      |\n",
      "| 13235 | RT @MykaMichael: It's funn... | Fri Sep 09 17:58:49 +0000 2016 |      0      |\n",
      "+-------+-------------------------------+--------------------------------+-------------+\n",
      "+-----------+-------------------------------+------------------------+\n",
      "| sentiment |           word_count          | probability_prediction |\n",
      "+-----------+-------------------------------+------------------------+\n",
      "|     1     | {'rt': 1L, 'land': 1L, 'de... |     0.999987932426     |\n",
      "|     1     | {'rt': 1L, 'land': 1L, 'de... |     0.999987932426     |\n",
      "|     1     | {'med': 1L, 'corn': 1L, 'i... |     0.999987884184     |\n",
      "|     1     | {'rt': 1L, 'httpstcotmrnnt... |     0.999987657816     |\n",
      "|     1     | {'a': 1L, 'we': 2L, 'chadp... |     0.99998606827      |\n",
      "|     -1    | {'and': 1L, 'is': 1L, 'arg... |     0.999982161599     |\n",
      "|     1     | {'rt': 1L, 'a': 1L, 'helpe... |     0.999981139291     |\n",
      "|     1     | {'a': 1L, 'sort': 1L, 'of'... |     0.99997984933      |\n",
      "|     1     | {'and': 2L, 'owl': 1L, 'mo... |     0.999977142442     |\n",
      "|     1     | {'and': 1L, 'a': 1L, 'abou... |     0.999976583053     |\n",
      "+-----------+-------------------------------+------------------------+\n",
      "[10 rows x 7 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print sentiment_model.predict(test_data, output_type='probability')\n",
    "test_data['probability_prediction']=sentiment_model.predict(test_data, output_type='probability')\n",
    "top20 = test_data.topk('probability_prediction', k=20)\n",
    "#print top20.column_names()\n",
    "print top20[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which of the following products are represented in the 20 most positive reviews? [multiple choice]\n",
    "\n",
    "\n",
    "Now, let us repeat this excercise to find the \"most negative reviews.\" Use the prediction probabilities to find the  20 reviews in the **test_data** with the **lowest probability** of being classified as a **positive review**. Repeat the same steps above but make sure you **sort in the opposite order**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------------+--------------------------------+-------------+\n",
      "|   X1  |              text             |              time              | prct_change |\n",
      "+-------+-------------------------------+--------------------------------+-------------+\n",
      "|  1068 | RT @seemaadhikari: ?????? ... | Fri Sep 09 07:24:09 +0000 2016 |      0      |\n",
      "|  3781 | RT @MrsJellySantos: Twizzl... | Fri Sep 09 11:45:39 +0000 2016 |      0      |\n",
      "| 13312 | RT @UWExtensionANRE: Check... | Fri Sep 09 18:01:38 +0000 2016 |      0      |\n",
      "|  5498 | RT @RootedinVermont: Cabot... | Fri Sep 09 13:09:04 +0000 2016 |      0      |\n",
      "|  1411 | Creppy fog over the corn f... | Fri Sep 09 07:56:11 +0000 2016 |      0      |\n",
      "|  3251 | RT @WISH_TV: Beasley's Cor... | Fri Sep 09 11:08:55 +0000 2016 |      0      |\n",
      "|  3242 | RT @WISH_TV: Beasley's Cor... | Fri Sep 09 11:08:17 +0000 2016 |      0      |\n",
      "|  5227 | RT @PHLBizJournal: 'Fancy'... | Fri Sep 09 12:55:36 +0000 2016 |      0      |\n",
      "|  6949 | Traders prepare for USDA r... | Fri Sep 09 14:11:31 +0000 2016 |      0      |\n",
      "|  822  | RT @SweetDealsUK: OPEN 9 -... | Fri Sep 09 07:02:24 +0000 2016 |      0      |\n",
      "+-------+-------------------------------+--------------------------------+-------------+\n",
      "+-----------+-------------------------------+------------------------+\n",
      "| sentiment |           word_count          | probability_prediction |\n",
      "+-----------+-------------------------------+------------------------+\n",
      "|     -1    | {'http\\x85': 1L, 'rt': 1L,... |    0.00222308108774    |\n",
      "|     -1    | {'rt': 1L, 'twizzlers': 1L... |    0.0022895146299     |\n",
      "|     -1    | {'httpstcoviqrcfweys': 1L,... |    0.00238788484042    |\n",
      "|     -1    | {'rt': 1L, 'kids': 1L, 'ht... |    0.00241671151623    |\n",
      "|     -1    | {'distance': 1L, 'what': 1... |    0.00244033302716    |\n",
      "|     -1    | {'rt': 1L, 'beasleys': 1L,... |    0.0026017101011     |\n",
      "|     -1    | {'rt': 1L, 'beasleys': 1L,... |    0.0026017101011     |\n",
      "|     -1    | {'rt': 1L, 'phlbizjournal'... |    0.00267389879297    |\n",
      "|     1     | {'a': 1L, 'and': 2L, 'litt... |    0.00273896218218    |\n",
      "|     -1    | {'httpstcoxahbiyvjpp': 1L,... |    0.00278649748479    |\n",
      "+-----------+-------------------------------+------------------------+\n",
      "[10 rows x 7 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bottom20 = test_data.topk('probability_prediction', k=20, reverse = True)\n",
    "print bottom20[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Quiz Question**: Which of the following products are represented in the 20 most negative reviews?  [multiple choice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute accuracy of the classifier\n",
    "\n",
    "We will now evaluate the accuracy of the trained classifer. Recall that the accuracy is given by\n",
    "\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified examples}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "This can be computed as follows:\n",
    "\n",
    "* **Step 1:** Use the trained model to compute class predictions (**Hint:** Use the `predict` method)\n",
    "* **Step 2:** Count the number of data points when the predicted class labels match the ground truth labels (called `true_labels` below).\n",
    "* **Step 3:** Divide the total number of correct predictions by the total number of data points in the dataset.\n",
    "\n",
    "Complete the function below to compute the classification accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_classification_accuracy(model, data, true_labels):\n",
    "    # First get the predictions\n",
    "    ## YOUR CODE HERE\n",
    "    predictions = model.predict(data)\n",
    "    correct_examples = []\n",
    "    # Compute the number of correctly classified examples\n",
    "    ## YOUR CODE HERE\n",
    "    for i in range(0,len(predictions)):\n",
    "        if predictions[i] != true_labels[i]: continue\n",
    "        else:\n",
    "            correct_examples.append(predictions[i])\n",
    "    # Then compute accuracy by dividing num_correct by total number of examples\n",
    "    ## YOUR CODE HERE\n",
    "    accuracy = len(correct_examples)/len(predictions)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute the classification accuracy of the **sentiment_model** on the **test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8149852119618797"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(sentiment_model, test_data, test_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: What is the accuracy of the **sentiment_model** on the **test_data**? Round your answer to 2 decimal places (e.g. 0.76). 1.00\n",
    "\n",
    "**Quiz Question**: Does a higher accuracy value on the **training_data** always imply that the classifier is better? Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn another classifier with fewer words\n",
    "\n",
    "There were a lot of words in the model we trained above. We will now train a simpler logistic regression model using only a subet of words that occur in the reviews. For this assignment, we selected a 20 words to work with. These are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "significant_words = ['bullish', 'bearish', 'rally']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(significant_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each review, we will use the **word_count** column and trim out all words that are **not** in the **significant_words** list above. We will use the [SArray dictionary trim by keys functionality]( https://dato.com/products/create/docs/generated/graphlab.SArray.dict_trim_by_keys.html). Note that we are performing this on both the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data['word_count_subset'] = train_data['word_count'].dict_trim_by_keys(significant_words, exclude=False)\n",
    "test_data['word_count_subset'] = test_data['word_count'].dict_trim_by_keys(significant_words, exclude=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the first example of the dataset looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A superhero corn cob with the sensibility to beat up spades in order to defeat birds.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **word_count** column had been working with before looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1L, 'spades': 1L, 'to': 2L, 'beat': 1L, 'corn': 1L, 'defeat': 1L, 'up': 1L, 'birds': 1L, 'sensibility': 1L, 'cob': 1L, 'in': 1L, 'superhero': 1L, 'the': 1L, 'with': 1L, 'order': 1L}\n"
     ]
    }
   ],
   "source": [
    "print train_data[0]['word_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are only working with a subet of these words, the column **word_count_subset** is a subset of the above dictionary. In this example, only 2 `significant words` are present in this review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print train_data[0]['word_count_subset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a logistic regression model on a subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now build a classifier with **word_count_subset** as the feature and **sentiment** as the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 12175</pre>"
      ],
      "text/plain": [
       "Number of examples          : 12175"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 1</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 2</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 3</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting Newton Method</pre>"
      ],
      "text/plain": [
       "Starting Newton Method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Elapsed Time | Training-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Elapsed Time | Training-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 2        | 0.018016     | 0.804682          |</pre>"
      ],
      "text/plain": [
       "| 1         | 2        | 0.018016     | 0.804682          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 3        | 0.030026     | 0.804682          |</pre>"
      ],
      "text/plain": [
       "| 2         | 3        | 0.030026     | 0.804682          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 4        | 0.043039     | 0.804682          |</pre>"
      ],
      "text/plain": [
       "| 3         | 4        | 0.043039     | 0.804682          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 5        | 0.056051     | 0.804682          |</pre>"
      ],
      "text/plain": [
       "| 4         | 5        | 0.056051     | 0.804682          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Class                          : LogisticClassifier\n",
       "\n",
       "Schema\n",
       "------\n",
       "Number of coefficients         : 3\n",
       "Number of examples             : 12175\n",
       "Number of classes              : 2\n",
       "Number of feature columns      : 1\n",
       "Number of unpacked features    : 2\n",
       "\n",
       "Hyperparameters\n",
       "---------------\n",
       "L1 penalty                     : 0.0\n",
       "L2 penalty                     : 0.01\n",
       "\n",
       "Training Summary\n",
       "----------------\n",
       "Solver                         : newton\n",
       "Solver iterations              : 4\n",
       "Solver status                  : SUCCESS: Optimal solution found.\n",
       "Training time (sec)            : 0.0601\n",
       "\n",
       "Settings\n",
       "--------\n",
       "Log-likelihood                 : 6012.1515\n",
       "\n",
       "Highest Positive Coefficients\n",
       "-----------------------------\n",
       "(intercept)                    : 1.4156\n",
       "word_count_subset[rally]       : 0.6638\n",
       "\n",
       "Lowest Negative Coefficients\n",
       "----------------------------\n",
       "word_count_subset[bearish]     : -2.1088"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model = graphlab.logistic_classifier.create(train_data,\n",
    "                                                   target = 'sentiment',\n",
    "                                                   features=['word_count_subset'],\n",
    "                                                   validation_set=None)\n",
    "simple_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the classification accuracy using the `get_classification_accuracy` function you implemented earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7962536970095301"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(simple_model, test_data, test_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will inspect the weights (coefficients) of the **simple_model**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">index</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">class</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">value</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">stderr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">(intercept)</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.41563657229</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0228703252504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">word_count_subset</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">rally</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.66379109091</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.06090098887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">word_count_subset</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">bearish</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-2.10876816318</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.22495520614</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[3 rows x 5 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tname\tstr\n",
       "\tindex\tstr\n",
       "\tclass\tint\n",
       "\tvalue\tfloat\n",
       "\tstderr\tfloat\n",
       "\n",
       "Rows: 3\n",
       "\n",
       "Data:\n",
       "+-------------------+---------+-------+----------------+-----------------+\n",
       "|        name       |  index  | class |     value      |      stderr     |\n",
       "+-------------------+---------+-------+----------------+-----------------+\n",
       "|    (intercept)    |   None  |   1   | 1.41563657229  | 0.0228703252504 |\n",
       "| word_count_subset |  rally  |   1   | 0.66379109091  |  1.06090098887  |\n",
       "| word_count_subset | bearish |   1   | -2.10876816318 |  1.22495520614  |\n",
       "+-------------------+---------+-------+----------------+-----------------+\n",
       "[3 rows x 5 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort the coefficients (in descending order) by the **value** to obtain the coefficients with the most positive effect on the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+-------+----------------+-----------------+\n",
      "|        name       |  index  | class |     value      |      stderr     |\n",
      "+-------------------+---------+-------+----------------+-----------------+\n",
      "|    (intercept)    |   None  |   1   | 1.41563657229  | 0.0228703252504 |\n",
      "| word_count_subset |  rally  |   1   | 0.66379109091  |  1.06090098887  |\n",
      "| word_count_subset | bearish |   1   | -2.10876816318 |  1.22495520614  |\n",
      "+-------------------+---------+-------+----------------+-----------------+\n",
      "[3 rows x 5 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simple_model.coefficients.sort('value', ascending=False).print_rows(num_rows=21)\n",
    "#sentiment_model.coefficients.sort('value', ascending=False).print_rows(num_rows=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Consider the coefficients of **simple_model**. There should be 21 of them, an intercept term + one for each word in **significant_words**. How many of the 20 coefficients (corresponding to the 20 **significant_words** and *excluding the intercept term*) are positive for the `simple_model`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------+--------------------------------+-------------+\n",
      "|  X1 |              text             |              time              | prct_change |\n",
      "+-----+-------------------------------+--------------------------------+-------------+\n",
      "| 802 |       Candy Corn Vampire      | Fri Sep 09 07:01:07 +0000 2016 |      0      |\n",
      "| 941 | Corn dogs, look like the d... | Fri Sep 09 07:14:38 +0000 2016 |      0      |\n",
      "| 917 | RT @busquetsmarcelo: $CORN... | Fri Sep 09 07:12:00 +0000 2016 |      0      |\n",
      "| 912 | King Corn - Aaron Woolf | ... | Fri Sep 09 07:11:38 +0000 2016 |      0      |\n",
      "| 883 | Pops Arcadia Corn Maze htt... | Fri Sep 09 07:08:33 +0000 2016 |      0      |\n",
      "| 874 | Reasons I like mexican Cok... | Fri Sep 09 07:07:23 +0000 2016 |      0      |\n",
      "| 870 | Slob On My Knob Like Corn ... | Fri Sep 09 07:06:59 +0000 2016 |      0      |\n",
      "| 845 | You can do it... grow and ... | Fri Sep 09 07:04:47 +0000 2016 |      0      |\n",
      "| 822 | RT @SweetDealsUK: OPEN 9 -... | Fri Sep 09 07:02:24 +0000 2016 |      0      |\n",
      "| 803 | South of the Border Chicke... | Fri Sep 09 07:01:14 +0000 2016 |      0      |\n",
      "+-----+-------------------------------+--------------------------------+-------------+\n",
      "+-----------+-------------------------------+------------------------+-------------------+\n",
      "| sentiment |           word_count          | probability_prediction | word_count_subset |\n",
      "+-----------+-------------------------------+------------------------+-------------------+\n",
      "|     -1    | {'corn': 1L, 'vampire': 1L... |     0.804653457104     |         {}        |\n",
      "|     -1    | {'wearing': 1L, 'look': 1L... |     0.804653457104     |         {}        |\n",
      "|     -1    | {'alza': 1L, 'rt': 1L, 'ah... |     0.804653457104     |         {}        |\n",
      "|     -1    | {'king': 1L, 'corn': 1L, '... |     0.804653457104     |         {}        |\n",
      "|     -1    | {'pops': 1L, 'maze': 1L, '... |     0.804653457104     |         {}        |\n",
      "|     -1    | {'mexican': 1L, 'like': 1L... |     0.804653457104     |         {}        |\n",
      "|     -1    | {'me': 1L, 'a': 1L, 'and':... |     0.804653457104     |         {}        |\n",
      "|     -1    | {'and': 2L, 'do': 1L, 'you... |     0.804653457104     |         {}        |\n",
      "|     -1    | {'httpstcoxahbiyvjpp': 1L,... |     0.804653457104     |         {}        |\n",
      "|     -1    | {'tortillas': 1L, 'of': 1L... |     0.804653457104     |         {}        |\n",
      "+-----------+-------------------------------+------------------------+-------------------+\n",
      "[10 rows x 8 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data['probability_prediction']=simple_model.predict(test_data, output_type='probability')\n",
    "top20 = test_data.topk('probability_prediction', k=20)\n",
    "#print top20.column_names()\n",
    "print top20[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Are the positive words in the **simple_model** (let us call them `positive_significant_words`) also positive words in the **sentiment_model**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype: str\n",
       "Rows: ?\n",
       "['AM markets: grains rally loses vim as weekend and Wasde loom https://t.co/qdxU0UzYil Corn, wheat', 'AM markets: grains rally loses vim as weekend and Wasde loom https://t.co/lHKo5u81pk Corn, wheat', '\"I don�t feel a small reduction is bullish, but it is supportive at the least.\" #corn #yield https://t.co/nFIMCiT1tF', '#corn rally off 3.16 level our analysis isolated. Settled &gt; weekly trend; 3.302 for week of 09/12. use as pivot. https://t.co/7z6b57T84A', 'ITALY NARDI RALLY DEEP CORN 330 MM STEERING WHEEL MAHOGANY WOOD POLISH SPOKE https://t.co/yrylbX7SbW https://t.co/0ZbnHWuJ9U', ... ]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data2 = test_data[test_data['word_count_subset'] != {}]\n",
    "test_data2['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compare the accuracy of the **sentiment_model** and the **simple_model** using the `get_classification_accuracy` method you implemented above.\n",
    "\n",
    "First, compute the classification accuracy of the **sentiment_model** on the **train_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.979440247046831"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(sentiment_model, train_data, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compute the classification accuracy of the **simple_model** on the **train_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8668150746537147"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(simple_model, train_data, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which model (**sentiment_model** or **simple_model**) has higher accuracy on the TRAINING set? Sentiment model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will repeat this excercise on the **test_data**. Start by computing the classification accuracy of the **sentiment_model** on the **test_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9145368370530358"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(sentiment_model, test_data, test_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will compute the classification accuracy of the **simple_model** on the **test_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8693004559635229"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(simple_model, test_data, test_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which model (**sentiment_model** or **simple_model**) has higher accuracy on the TEST set? Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Majority class prediction\n",
    "\n",
    "It is quite common to use the **majority class classifier** as the a baseline (or reference) model for comparison with your classifier model. The majority classifier model predicts the majority class for all data points. At the very least, you should healthily beat the majority class classifier, otherwise, the model is (usually) pointless.\n",
    "\n",
    "What is the majority class in the **train_data**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112164\n",
      "21252\n"
     ]
    }
   ],
   "source": [
    "num_positive  = (train_data['sentiment'] == +1).sum()\n",
    "num_negative = (train_data['sentiment'] == -1).sum()\n",
    "print num_positive\n",
    "print num_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the accuracy of the majority class classifier on **test_data**.\n",
    "\n",
    "**Quiz Question**: Enter the accuracy of the majority class classifier model on the **test_data**. Round your answer to two decimal places (e.g. 0.76)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842782577394\n"
     ]
    }
   ],
   "source": [
    "num_positive_test  = (test_data['sentiment'] == +1).sum()\n",
    "num_negative_test = (test_data['sentiment'] == -1).sum()\n",
    "print num_positive_test/len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Is the **sentiment_model** definitely better than the majority class classifier (the baseline)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Yes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-3ae2ea0c3867>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mYes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Yes' is not defined"
     ]
    }
   ],
   "source": [
    "Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
